from __future__ import annotationsimport argparseimport shutilfrom pathlib import Pathimport pandas as pdfrom astropy.table import Tablefrom pykoa.koa import Koafrom tqdm import tqdmdef ensure_dir(p: Path) -> None:    p.mkdir(parents=True, exist_ok=True)def query_to_ipac(instrument: str, target: str, date_start: str, date_end: str, outpath: Path) -> None:    params = {        "instrument": instrument.lower(),        "target": target,        "date": f"{date_start}/{date_end}",    }    Koa.query_criteria(params, str(outpath), overwrite=True, format="ipac")def query_by_radec(    instrument: str,    ra: float,    dec: float,    radius_arcsec: float,    date_start: str,    date_end: str,    outpath: Path,) -> None:    """RA/Dec cone search fallback for KOA (radius_arcsec converted to degrees)."""    radius_deg = radius_arcsec / 3600.0    params = {        "instrument": instrument.lower(),        "ra": ra,        "dec": dec,        "radius": radius_deg,        "date": f"{date_start}/{date_end}",    }    Koa.query_criteria(params, str(outpath), overwrite=True, format="ipac")def has_rows(ipac_path: Path) -> bool:    """True only if the IPAC table contains at least one real KOAID. """    if not ipac_path.exists():        return False    try:        t = Table.read(str(ipac_path), format="ipac")        if len(t) == 0 or "koaid" not in t.colnames:            return False        koaids = [str(x).strip().lower() for x in t["koaid"]]        real = [k for k in koaids if k not in ("", "null", "none")]        return len(real) > 0    except Exception:        return Falsedef download_koaproducts(    ipac_path: Path,    outdir: Path,    *,    lev0file: int,    lev1file: int,    calibfile: int = 0,) -> None:    ensure_dir(outdir)    Koa.download(        str(ipac_path),        "ipac",        str(outdir),        lev0file=lev0file,        lev1file=lev1file,        calibfile=calibfile,        calibdir=1,    )def organize_hires_lev1_extracted(outdir: Path) -> None:       src = outdir / "lev1" / "binaryfits"    if not src.exists():        print(f"[HIRES] expected folder not found: {src}")        return    dst = outdir / "lev1" / "extracted"    dst.mkdir(parents=True, exist_ok=True)    flux_dirs = list(src.rglob("flux"))    if not flux_dirs:        print(f"[HIRES] no flux directories found under {src}")        return    fits_files: list[Path] = []    for fd in flux_dirs:        fits_files.extend(fd.rglob("*.fits"))        fits_files.extend(fd.rglob("*.fits.gz"))    fits_files = sorted(set(fits_files))    if not fits_files:        print(f"[HIRES] no FITS files found under flux directories in {src}")        return    kept = 0    for f in fits_files:        stem = f.name  # e.g., HI.20200817.27025_1_03_flux.fits.gz        if stem.startswith("HI."):            exposure_id = stem.split("_")[0]  # HI.20200817.27025        else:            exposure_id = "unknown"        sub = dst / exposure_id        sub.mkdir(parents=True, exist_ok=True)        # f is .../ccdX/flux/<file> so parent.parent is ccdX        ccd = f.parent.parent.name        out_name = f"{ccd}__{stem}"        shutil.copy2(f, sub / out_name)        kept += 1    print(f"[HIRES] copied {kept} extracted spectrum FITS file(s) from flux/ into {dst}")def choose_target_name(row: pd.Series) -> str:    hostname = str(row.get("hostname", "")).strip()    pl_name = str(row.get("pl_name", "")).strip()    return hostname if hostname else pl_namedef main() -> None:    ap = argparse.ArgumentParser()    ap.add_argument(        "--targets",        default="ASTR502_Master_Target_List.csv",        help="Master target list (expects columns like hostname/pl_name, ra, dec).",    )    ap.add_argument("--data-root", default="data/koa", help="Root directory for KOA downloads")    ap.add_argument("--meta-root", default="metadata/koa", help="Root directory for KOA metadata tables")    ap.add_argument("--cookie", default="", help="Optional KOA cookie path for proprietary access")    ap.add_argument(        "--instruments",        default="HIRES",        help="KOA instruments to attempt (pipe-separated), e.g. HIRES|ESI|KPF",    )    ap.add_argument("--date-start", default="1994-01-01", help="Start date YYYY-MM-DD")    ap.add_argument("--date-end", default="2026-12-31", help="End date YYYY-MM-DD")    ap.add_argument("--radius-arcsec", type=float, default=30.0, help="Cone radius (arcsec) for RA/Dec fallback")    ap.add_argument("--max-targets", type=int, default=0, help="If >0, only process first N targets (debug)")    args = ap.parse_args()    if args.cookie:        ensure_dir(Path(args.cookie).parent)        Koa.login(args.cookie)    df = pd.read_csv(args.targets)    data_root = Path(args.data_root)    meta_root = Path(args.meta_root)    ensure_dir(data_root)    ensure_dir(meta_root)    requested = [x.strip().upper() for x in str(args.instruments).split("|") if x.strip()]    allowed = {"HIRES", "ESI", "KPF"}    instruments = [i for i in requested if i in allowed]    if not instruments:        raise ValueError(f"No recognized instruments in --instruments='{args.instruments}'")    if args.max_targets and args.max_targets > 0:        df = df.head(args.max_targets)    for _, row in tqdm(df.iterrows(), total=len(df), desc="Targets"):        target = choose_target_name(row)        if not target:            continue        date_start = args.date_start        date_end = args.date_end        safe_name = target.replace(" ", "_").replace("/", "_")        for inst in instruments:            inst_lower = inst.lower()            meta_path = meta_root / inst / f"{safe_name}_{date_start}_{date_end}.tbl"            ensure_dir(meta_path.parent)            print(f"\n[{inst}] querying {target} ({date_start} → {date_end})")            # 1) Name query            try:                query_to_ipac(inst_lower, target, date_start, date_end, meta_path)            except Exception as e:                print(f"[{inst}] name query failed for {target}: {e}")            # 2) RA/Dec fallback            if not has_rows(meta_path):                try:                    ra = float(row["ra"])                    dec = float(row["dec"])                    print(f"[{inst}] no name match; retrying with RA/Dec ({ra}, {dec}), r={args.radius_arcsec} arcsec")                    query_by_radec(                        inst_lower,                        ra,                        dec,                        radius_arcsec=args.radius_arcsec,                        date_start=date_start,                        date_end=date_end,                        outpath=meta_path,                    )                except Exception as e:                    print(f"[{inst}] RA/Dec query failed for {target}: {e}")            if not has_rows(meta_path):                print(f"[{inst}] no rows returned for {target} (name + RA/Dec)")                continue            outdir = data_root / inst / safe_name            if inst == "HIRES":                # Skip re-download if lev1 already exists                if (outdir / "lev1" / "binaryfits").exists():                    print(f"[{inst}] lev1 already exists, skipping download → {outdir}")                else:                    print(f"[{inst}] downloading EXTRACTED spectra (Level 1) ONLY → {outdir}")                    download_koaproducts(meta_path, outdir, lev0file=0, lev1file=1, calibfile=0)                organize_hires_lev1_extracted(outdir)            elif inst == "ESI":                print(f"[{inst}] downloading RAW (Level 0) → {outdir}")                download_koaproducts(meta_path, outdir, lev0file=1, lev1file=0, calibfile=0)            elif inst == "KPF":                print(f"[{inst}] attempting Level 1 download (if available) → {outdir}")                download_koaproducts(meta_path, outdir, lev0file=0, lev1file=1, calibfile=0)    print("\nDone.")if __name__ == "__main__":    main()